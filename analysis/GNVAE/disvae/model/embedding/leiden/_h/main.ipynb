{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leiden and igraph\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import igraph as ig\n",
    "import leidenalg\n",
    "import re\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "# Ensembl ID to Entrez ID conversion\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "\n",
    "# GO analysis\n",
    "from goatools.base import download_go_basic_obo\n",
    "from goatools.base import download_ncbi_associations\n",
    "from goatools.obo_parser import GODag\n",
    "from goatools.anno.genetogo_reader import Gene2GoReader\n",
    "from goatools.goea.go_enrichment_ns import GOEnrichmentStudyNS\n",
    "\n",
    "\n",
    "# Word cloud\n",
    "import wordcloud\n",
    "import math\n",
    "import random\n",
    "\n",
    "# GTF parser for Ensembl ID to gene symbol conversion\n",
    "from gtfparse import read_gtf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_variables_to_leiden(df, n_neighbors, directed, seed):\n",
    "    \n",
    "    adjacency = kneighbors_graph(df, n_neighbors, mode='connectivity', include_self=False)\n",
    "    \n",
    "    distance = kneighbors_graph(df, n_neighbors, mode='distance', include_self=False)\n",
    "    \n",
    "    sources, targets = adjacency.nonzero()\n",
    "\n",
    "    # weight is inverse distance squared\n",
    "\n",
    "    weights = 1 /  distance[sources, targets].A1 ** 2\n",
    "\n",
    "    \n",
    "    g = ig.Graph(directed=directed)\n",
    "    g.add_vertices(adjacency.shape[0])  # this adds adjacency.shape[0] vertices\n",
    "    g.add_edges(list(zip(sources, targets)))\n",
    "    g.es['weight'] = weights\n",
    "    \n",
    "    part = leidenalg.find_partition(g, leidenalg.ModularityVertexPartition, weights='weight', seed=seed)\n",
    "    \n",
    "    \n",
    "    membership_df = pd.DataFrame({'cluster_id':part.membership}, index=df.index)\n",
    "    \n",
    "    return (membership_df, part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensembl to Entrez\n",
    "\n",
    "class EnsemblIDToEntrezIDConverter():\n",
    "    def __init__(self):\n",
    "        with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "            df_a = ro.conversion.rpy2py(ro.r('''\n",
    "                                             library(org.Hs.eg.db)\n",
    "                                             as.data.frame(org.Hs.egENSEMBL)\n",
    "                                            '''))\n",
    "            self.entrez_ensembl_df = df_a.groupby(['ensembl_id']).first()\n",
    "    \n",
    "    def convert(self, gene_list_or_set):\n",
    "        \n",
    "        ensembl_id_df = pd.DataFrame(index = { re.sub(\"\\..*$\",\"\",x) for x in gene_list_or_set })\n",
    "        entrez_ids = set(ensembl_id_df.merge(self.entrez_ensembl_df, left_index=True, right_index=True)['gene_id'].astype(int))\n",
    "        return entrez_ids\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "# Gene Ontology\n",
    "    \n",
    "def get_entrez_ensembl_df():\n",
    "    with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "        df_a = ro.conversion.rpy2py(ro.r('''\n",
    "                                         library(org.Hs.eg.db)\n",
    "                                         as.data.frame(org.Hs.egENSEMBL)\n",
    "                                        '''))\n",
    "        entrez_ensembl_df = df_a.groupby(['ensembl_id']).first()\n",
    "        return entrez_ensembl_df\n",
    "\n",
    "\n",
    "class MyGeneOntologyAnalysis():\n",
    "    def __init__(self):\n",
    "        \n",
    "\n",
    "        obo_fname = download_go_basic_obo()\n",
    "        file_gene2go = download_ncbi_associations()\n",
    "        obodag = GODag(\"go-basic.obo\")\n",
    "\n",
    "        # Read NCBI's gene2go. Store annotations in a list of namedtuples\n",
    "        objanno = Gene2GoReader(file_gene2go, taxids=[9606])\n",
    "\n",
    "        # Get associations for each branch of the GO DAG (BP, MF, CC)\n",
    "        ns2assoc = objanno.get_ns2assc()\n",
    "\n",
    "        for nspc, id2gos in ns2assoc.items():\n",
    "            print(\"{NS} {N:,} annotated human genes\".format(NS=nspc, N=len(id2gos)))\n",
    "          \n",
    "        genes_with_annotation = set.union(*(set(x.keys()) for x in ns2assoc.values()))\n",
    "\n",
    "        \n",
    "        self.alpha = 0.05\n",
    "        \n",
    "        self.goeaobj = GOEnrichmentStudyNS(\n",
    "            genes_with_annotation, # List of human genes\n",
    "            ns2assoc, # geneid/GO associations\n",
    "            obodag, # Ontologies\n",
    "            propagate_counts = False,\n",
    "            alpha = self.alpha, # default significance cut-off\n",
    "            methods = ['fdr_bh']) # defult multipletest correction method\n",
    "        \n",
    "        \n",
    "\n",
    "    def goea_results_all(self, gene_set):\n",
    "        return self.goeaobj.run_study(gene_set)\n",
    "    \n",
    "    \n",
    "    def goea_results_significant(self, gene_set):\n",
    "        all_results = self.goea_results_all(gene_set)\n",
    "        return [r for r in all_results if r.p_fdr_bh < self.alpha]\n",
    "    \n",
    "    \n",
    "\n",
    "# Word cloud\n",
    "    \n",
    "class GeneOntologyWordCloud():\n",
    "    def __init__(self):\n",
    "        self.wc = wordcloud.WordCloud(colormap='rainbow', \n",
    "                             stopwords=['integral', 'component', 'of', 'process', 'activity', 'to'],\n",
    "                             collocations = True,\n",
    "                             ranks_only=True,\n",
    "                         )\n",
    "        \n",
    "    def gen_random_text(self):\n",
    "        # Generate a spacer between gene ontology terms\n",
    "        return ' '.join(''.join((random.choice('abcdefghijklmnopqrstuvwxyz') for _ in range(150))) for _ in range(3))\n",
    "        \n",
    "    def goea_to_text(self, goea_results):\n",
    "        # Generate a text concatenating GO term names, each name being repeated proportionally to the minus log of its pvalue\n",
    "        return ' '.join((''.join( ' ' + self.gen_random_text() + ' ' + x.name for _ in range(int((-10) * math.log2(x.p_uncorrected))))\n",
    "                for x in goea_results  if x.enrichment == 'e'))\n",
    "    \n",
    "    def generate_image(self, goea_results):\n",
    "        return self.wc.generate(self.goea_to_text(goea_results)).to_image()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gtf_genes_df():\n",
    "    try:\n",
    "        gtf_df_genes = pd.read_csv(\"gtf_df_genes.csv\")\n",
    "    except:\n",
    "        gtf_df = read_gtf(\"/ceph/genome/human/gencode25/gtf.CHR/_m/gencode.v25.annotation.gtf\")\n",
    "        gtf_df_genes = gtf_df[gtf_df[\"feature\"] == \"gene\"][['gene_id', 'gene_name']]\n",
    "        gtf_df_genes.to_csv(\"gtf_df_genes.csv\", index=None)\n",
    "        \n",
    "    return gtf_df_genes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterGOWordCloud():\n",
    "    def __init__(self, n_neighbors, directed, seed):\n",
    "        \n",
    "        self.n_neighbors = n_neighbors\n",
    "        expression_df = pd.read_csv('../../_m/latent_variables.csv', index_col=0)\n",
    "        mucols = [x for x in expression_df.columns if 'mu' in x]\n",
    "        self.expression_df = expression_df[mucols]\n",
    "        \n",
    "        \n",
    "        \n",
    "        (self.mdf, self.part) =  latent_variables_to_leiden(self.expression_df, n_neighbors, directed, seed)\n",
    "        \n",
    "        \n",
    "        self.gtf_df_genes = get_gtf_genes_df()\n",
    "\n",
    "        self.e2e = EnsemblIDToEntrezIDConverter()\n",
    "        self.mygoa = MyGeneOntologyAnalysis()\n",
    "        self.gowc = GeneOntologyWordCloud()\n",
    "    \n",
    "    \n",
    "    def cluster_df(self, cluster_id):\n",
    "        \n",
    "        return self.expression_df.iloc[self.part[cluster_id]][[]]\\\n",
    "        .merge(cgowc.gtf_df_genes, left_index=True, right_on='gene_id', how='left')\\\n",
    "        .set_index('gene_id')\n",
    "        \n",
    "    \n",
    "    def pipeline(self, cluster_id, filename_prefix):\n",
    "        \n",
    "        #with open(\"%s_neighbors.txt\" % filename_prefix, \"wt\") as f:\n",
    "        #    for x in nn:\n",
    "        #        print(x, file=f)\n",
    "\n",
    "        #self.gn.neighbors_df(gene_id, self.n_neighbors)\\\n",
    "        #.to_csv(\"%s_neighbors.csv\" % filename_prefix)\n",
    "        \n",
    "        #nn = self.gn.neighbors(gene_id, self.n_neighbors)\n",
    "        \n",
    "        self.cluster_df(cluster_id).to_csv(\"%s_genes.csv\" % filename_prefix)\n",
    "        \n",
    "        nn = set((self.expression_df.index[x] for x in self.part[cluster_id]))\n",
    "                \n",
    "        go_r = self.mygoa.goea_results_significant(self.e2e.convert(nn))\n",
    "        self.mygoa.goeaobj.wr_tsv(\"%s_go_enrichment.tsv\" % filename_prefix, go_r)\n",
    "        \n",
    "        if len(go_r) > 0:\n",
    "            p = self.gowc.generate_image(go_r)\n",
    "            p.save(\"%s_go_wordcloud.png\" % filename_prefix)\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgowc = ClusterGOWordCloud(8, False, 1092333)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cgowc.part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [x for x in range(len(cgowc.part)) if 1 in cgowc.part[x]][0]\n",
    "print(\"D2 junction 5-6 is in module\", a)\n",
    "\n",
    "a = [x for x in range(len(cgowc.part)) if 0 in cgowc.part[x]][0]\n",
    "print(\"D2 junction 5-7 is in module\", a)\n",
    "\n",
    "d = {z[0]:z[1]  for z in zip(cgowc.gtf_df_genes['gene_name'], cgowc.gtf_df_genes['gene_id'])}\n",
    "a = cgowc.mdf.loc[d['SETD1A'], 'cluster_id']\n",
    "print(\"SETD1A is in module\", a)\n",
    "\n",
    "a = cgowc.mdf.loc[d['DRD2'], 'cluster_id']\n",
    "print(\"DRD2 is in module\", a)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GWAS, TWAS and DE enrichment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_genes = set(pd.read_csv('/ceph/projects/v4_phase3_paper/analysis/differential_expression/_m/genes/diffExpr_szVctl_FDR05.txt',\n",
    "                      sep='\\t', usecols=[0], index_col=0).index)\n",
    "len(de_genes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_twas_genes():\n",
    "    df = pd.read_csv('/ceph/projects/v4_phase3_paper/analysis/twas/results_tables/pgc2/_m/gene_twas_results_including_MHC.csv')\n",
    "    return set(df[df['TWAS.P.fdr_bh'] < .05]['gene_id'])\n",
    "\n",
    "\n",
    "twas_genes = get_twas_genes()\n",
    "len(twas_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas_genes = set(pd.read_csv('/ceph/projects/v4_phase3_paper/inputs/sz_gwas/pgc2_clozuk/table_s3/hg38/genes/_m/gwas_genes.csv')['gene_id'])\n",
    "len(gwas_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mhc_genes = set(pd.read_csv('/ceph/projects/v4_phase3_paper/inputs/sz_gwas/pgc2_clozuk/table_s3/hg38/mhc_region_genes/_m/mhc_genes.csv')['gene_id'])\n",
    "len(mhc_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fet(a, b, u):\n",
    "    # a, b, u are sets\n",
    "    # u is the universe\n",
    "    \n",
    "    yes_a = u.intersection(a)\n",
    "    yes_b = u.intersection(b)\n",
    "    no_a = u - a\n",
    "    no_b = u - b\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    m = [[len(yes_a.intersection(yes_b)), len(no_a.intersection(yes_b)) ], \n",
    "                               [len(yes_a.intersection(no_b)), len(no_a.intersection(no_b))]]\n",
    "    return stats.fisher_exact(m) #, m, len(yes_b)/len(u), len(yes_a)/len(u), len(yes_a.intersection(yes_b)) * len(no_a.intersection(no_b)) / (len(yes_a.intersection(no_b)) * len(no_a.intersection(yes_b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrichment_rows():\n",
    "    part = cgowc.part\n",
    "    df = cgowc.expression_df\n",
    "    u = set(cgowc.expression_df.index[3:])\n",
    "    for ii in range(len(part)):\n",
    "        a = set((df.index[x] for x in part[ii]))\n",
    "        yield (ii,\n",
    "               len(part[ii]),\n",
    "               *fet(a, gwas_genes, u),\n",
    "               *fet(a, twas_genes, u),\n",
    "               *fet(a, de_genes, u),\n",
    "               )\n",
    "        \n",
    "    #print(ii, 0 in part[ii], 1 in part[ii], fet(a, gwas_genes, u), fet(a, twas_genes, u), fet(a, de_genes, u), len(part[ii]))\n",
    "    \n",
    "edf1 = pd.DataFrame.from_records(enrichment_rows(), \n",
    "                                 columns=['module_id', 'n_genes', 'gwas_or', 'gwas_p', 'twas_or', 'twas_p', 'de_or', 'de_p'],\n",
    "                                 index='module_id')\n",
    "edf1['twas_fdr_bh'] = multipletests(edf1['twas_p'], method='fdr_bh')[1]\n",
    "edf1['gwas_fdr_bh'] = multipletests(edf1['gwas_p'], method='fdr_bh')[1]\n",
    "edf1['de_fdr_bh'] = multipletests(edf1['de_p'], method='fdr_bh')[1]\n",
    "\n",
    "edf1[['n_genes', 'gwas_or', 'gwas_p', 'gwas_fdr_bh', 'twas_or', 'twas_p', 'twas_fdr_bh', 'de_or', 'de_p', 'de_fdr_bh']].to_csv('module_enrichment.csv')\n",
    "\n",
    "edf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrichment_rows_nomhc():\n",
    "    part = cgowc.part\n",
    "    df = cgowc.expression_df\n",
    "    u = set(cgowc.expression_df.index[3:]) - mhc_genes\n",
    "    for ii in range(len(part)):\n",
    "        a = set((df.index[x] for x in part[ii])) - mhc_genes\n",
    "        yield (ii,\n",
    "               len(part[ii]),\n",
    "               *fet(a, gwas_genes - mhc_genes, u),\n",
    "               *fet(a, twas_genes - mhc_genes, u),\n",
    "               *fet(a, de_genes - mhc_genes, u),\n",
    "              )\n",
    "        \n",
    "    #print(ii, 0 in part[ii], 1 in part[ii], fet(a, gwas_genes, u), fet(a, twas_genes, u), fet(a, de_genes, u), len(part[ii]))\n",
    "    \n",
    "edf2 = pd.DataFrame.from_records(enrichment_rows_nomhc(), \n",
    "                                columns=['module_id', 'n_genes', 'gwas_or', 'gwas_p', 'twas_or', 'twas_p', 'de_or', 'de_p'],\n",
    "                                index='module_id')\n",
    "edf2['twas_fdr_bh'] = multipletests(edf2['twas_p'], method='fdr_bh')[1]\n",
    "edf2['gwas_fdr_bh'] = multipletests(edf2['gwas_p'], method='fdr_bh')[1]\n",
    "edf2['de_fdr_bh'] = multipletests(edf2['de_p'], method='fdr_bh')[1]\n",
    "\n",
    "edf2[['n_genes', 'gwas_or', 'gwas_p', 'gwas_fdr_bh', 'twas_or', 'twas_p', 'twas_fdr_bh', 'de_or', 'de_p', 'de_fdr_bh']].to_csv('module_enrichment_excluding_mhc_region.csv')\n",
    "\n",
    "edf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GO enrichment for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pipeline for each cluster\n",
    "for cluster_id in range(len(cgowc.part)):\n",
    "    cgowc.pipeline(cluster_id, 'module%d' % cluster_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
