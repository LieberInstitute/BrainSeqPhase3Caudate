{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichment and Overlap of PGC2+CLOZUK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, errno\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import *\n",
    "from pandas_plink import read_plink\n",
    "from warnings import filterwarnings\n",
    "from matplotlib.cbook import mplDeprecation\n",
    "from scipy.stats import fisher_exact, binom_test\n",
    "\n",
    "filterwarnings(\"ignore\",category=mplDeprecation)\n",
    "filterwarnings('ignore', category=UserWarning, module='plotnine.*')\n",
    "filterwarnings('ignore', category=DeprecationWarning, module='plotnine.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'biomart_file': '../_h/biomart.csv',\n",
    "    'phenotype_file': '/ceph/projects/v4_phase3_paper/inputs/phenotypes/_m/merged_phenotypes.csv',\n",
    "    'plink_file_prefix': '/ceph/projects/v4_phase3_paper/inputs/genotypes/_m/LIBD_Brain_TopMed',\n",
    "    'gwas_snp_file': '/ceph/projects/v4_phase3_paper/inputs/sz_gwas/pgc2_clozuk/map_phase3/_m/libd_hg38_pgc2sz_snps.tsv'\n",
    "}\n",
    "\n",
    "config_feature = {\n",
    "    'de_file': '../../differential_expression/_m/transcripts/diffExpr_szVctl_full.txt',\n",
    "    'residual_expression_file': '../../differential_expression/_m/transcripts/residualized_expression.tsv',\n",
    "    'fastqtl_output_file': '../../eqtl/caudate/summary_table/_m/Brainseq_LIBD_caudate_4features.signifpairs.txt.gz',\n",
    "}\n",
    "\n",
    "feature = \"transcripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache()\n",
    "def feature_map(feature):\n",
    "    return {\"genes\": \"Gene\", \"transcripts\": \"Transcript\", \n",
    "            \"exons\": \"Exon\", \"junctions\": \"Junction\"}[feature]\n",
    "\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_de_df():\n",
    "    \"\"\"\n",
    "    Load DE analysis\n",
    "    \"\"\"\n",
    "    return pd.read_csv(config_feature['de_file'], sep='\\t', index_col=0)\n",
    "\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_eqtl_df():\n",
    "    eqtl_df = pd.read_csv(config_feature['fastqtl_output_file'], sep='\\t')\n",
    "    return eqtl_df[(eqtl_df[\"Type\"] == feature_map(feature))]\n",
    "\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_gwas_snps():\n",
    "    return pd.read_csv(config['gwas_snp_file'], sep='\\t', index_col=0, low_memory=False)\n",
    "\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_integration_df():\n",
    "    return get_gwas_snps().merge(get_eqtl_df(), left_on='our_snp_id', right_on='variant_id', \n",
    "                                 suffixes=['_PGC2', '_eQTL'])\\\n",
    "                          .merge(get_de_df(), left_on='gene_id', right_index=True)\n",
    "\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_residual_expression_df():\n",
    "    return pd.read_csv(config_feature['residual_expression_file'], \n",
    "                       sep='\\t', index_col=0).transpose()\n",
    "\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_pheno_df():\n",
    "    return pd.read_csv(config['phenotype_file'], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agree_direction(row):\n",
    "    return [-1, 1][row['pgc2_a1_same_as_our_counted']] * np.sign(row['OR'] - 1) * np.sign(row['slope']) * np.sign(row['t'])\n",
    "\n",
    "\n",
    "def letter_snp(number, a0, a1):\n",
    "    '''\n",
    "    Example:\n",
    "    letter_snp(0, 'A', 'G') is 'AA'\n",
    "    letter_snp(1, 'A', 'G') is 'AG'\n",
    "    letter_snp(2, 'A', 'G') is 'GG'\n",
    "    \n",
    "    '''\n",
    "    if np.isnan(number):\n",
    "        return np.nan\n",
    "    if len(a0)==1 and len(a1)==1:\n",
    "        sep = ''\n",
    "    else:\n",
    "        sep = ' '\n",
    "    return sep.join(sorted([a0]*int(number) + [a1]*(2-int(number))))\n",
    "\n",
    "\n",
    "def get_gwas_snp(snp_id):\n",
    "    gwas = get_gwas_snps()\n",
    "    r = gwas[gwas['our_snp_id']==snp_id]\n",
    "    assert len(r) == 1\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache()\n",
    "def get_expression_and_pheno_df():\n",
    "    return pd.merge(get_pheno_df(), get_residual_expression_df(), left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_plink_tuple():\n",
    "    '''\n",
    "    Usage: (bim, fam, bed) = get_plink_tuple()\n",
    "    '''\n",
    "    return read_plink(config['plink_file_prefix'])\n",
    "\n",
    "\n",
    "@functools.lru_cache()\n",
    "def subset_bed():\n",
    "    \"\"\"\n",
    "    This subsets the bed and bim file and returns the new subsetted\n",
    "    data with shared brain_ids.\n",
    "    \n",
    "    This is to speed up accessing the bed file.\n",
    "    \"\"\"\n",
    "    (bim, fam, bed) = get_plink_tuple()\n",
    "    brain_ids = list(set(get_expression_and_pheno_df()['BrNum']).intersection(set(fam['fid'])))\n",
    "    fam_pos = list(fam[(fam[\"fid\"].isin(brain_ids))].drop_duplicates(subset=\"fid\").loc[:, 'i'])\n",
    "    unique_snps = get_eqtl_df().variant_id.unique()\n",
    "    snp_info = bim[(bim[\"snp\"].isin(unique_snps))].copy()\n",
    "    snp_pos = list(snp_info.loc[:, \"i\"])\n",
    "    new_bed = bed[snp_pos].compute()[:,fam_pos]\n",
    "    new_bim = bim[(bim[\"i\"].isin(snp_pos))].reset_index(drop=True)\n",
    "    new_bim['ii'] = new_bim.index\n",
    "    return new_bed, new_bim, brain_ids\n",
    "\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_snp_df(snp_id):\n",
    "    '''\n",
    "    Returns a dataframe containing the genotype on snp snp_id.\n",
    "    The allele count is the same as in the plink files.\n",
    "    \n",
    "    Example: \n",
    "    get_snp_df('rs653953').head(5)\n",
    "    \n",
    "            rs653953_num rs653953_letter rs653953\n",
    "    Br5168             0              GG    0\\nGG\n",
    "    Br2582             1              AG    1\\nAG\n",
    "    Br2378             1              AG    1\\nAG\n",
    "    Br5155             2              AA    2\\nAA\n",
    "    Br5182             2              AA    2\\nAA\n",
    "    '''\n",
    "    bed, bim, brain_ids = subset_bed()\n",
    "    snp_info = bim[bim['snp']==snp_id]\n",
    "    snp_pos = snp_info.iloc[0]['ii']\n",
    "    dfsnp = pd.DataFrame(bed[[snp_pos]], columns=brain_ids, index=[snp_id + '_num']).transpose().dropna()\n",
    "    my_letter_snp = functools.partial(letter_snp, a0=snp_info.iloc[0]['a0'], a1=snp_info.iloc[0]['a1'])\n",
    "    # the 2 - in next line is to workaround a possible bug in pandas_plink? a1 and a0 inverted\n",
    "    dfsnp[[snp_id + '_num']] = 2 - dfsnp[[snp_id + '_num']].astype('int')\n",
    "    dfsnp[snp_id + '_letter'] = dfsnp[snp_id + '_num'].apply(my_letter_snp)\n",
    "    dfsnp[snp_id] = (dfsnp[snp_id + '_num'].astype('str') + '\\n' + \n",
    "                     dfsnp[snp_id + '_letter'].astype('str')).astype('category')\n",
    "    return dfsnp\n",
    "\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_gwas_ordered_snp_df(snp_id):\n",
    "    '''\n",
    "    Returns a dataframe containing the genotype on snp snp_id.\n",
    "    The allele count is the number of risk alleles according to GWAS.\n",
    "    \n",
    "    Example: \n",
    "    get_gwas_ordered_snp_df('rs653953').head(5)\n",
    "    \n",
    "            rs653953_num rs653953_letter rs653953\n",
    "    Br5168             2              GG    2\\nGG\n",
    "    Br2582             1              AG    1\\nAG\n",
    "    Br2378             1              AG    1\\nAG\n",
    "    Br5155             0              AA    0\\nAA\n",
    "    Br5182             0              AA    0\\nAA\n",
    "    '''\n",
    "    pgc = get_gwas_snps()\n",
    "    dfsnp = get_snp_df(snp_id).copy()\n",
    "    gwas_snp = get_gwas_snp(snp_id)\n",
    "    \n",
    "    if gwas_snp['pgc2_a1_same_as_our_counted'].iloc[0]:\n",
    "        if gwas_snp['OR'].iloc[0] > 1:\n",
    "            pass\n",
    "        else:\n",
    "            dfsnp[[snp_id + '_num']] = 2 - dfsnp[[snp_id + '_num']]\n",
    "    else:\n",
    "        if gwas_snp['OR'].iloc[0] > 1:\n",
    "            dfsnp[[snp_id + '_num']] = 2 - dfsnp[[snp_id + '_num']]\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    dfsnp[snp_id] = (dfsnp[snp_id + '_num'].astype('str') + '\\n' + \n",
    "                     dfsnp[snp_id + '_letter'].astype('str')).astype('category')\n",
    "    return dfsnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache()\n",
    "def get_biomart_df():\n",
    "    biomart = pd.read_csv(config['biomart_file'])\n",
    "    biomart['description'] = biomart['description'].str.replace('\\[Source.*$','', regex=True)\n",
    "    return biomart\n",
    "\n",
    "\n",
    "def get_gene_symbol(gene_id, biomart=get_biomart_df()):\n",
    "    ensge = re.sub('\\..+$','', gene_id)\n",
    "    ggg = biomart[biomart['ensembl_gene_id']==ensge]\n",
    "    if ggg.shape[0]==0:\n",
    "        return '', ''\n",
    "\n",
    "    gs = ggg['external_gene_name'].values[0]\n",
    "    de = ggg['description'].values[0]\n",
    "    if type(de)!=str:\n",
    "        de = ''\n",
    "    de = re.sub('\\[Source:.*$','',de)\n",
    "    return gs, de\n",
    "\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_risk_allele(snp_id):\n",
    "    gwas_snp = get_gwas_snp(snp_id)\n",
    "    if gwas_snp['OR'].iloc[0] > 1:\n",
    "        ra = gwas_snp['A1'].iloc[0]\n",
    "    else:\n",
    "        ra = gwas_snp['A2'].iloc[0]\n",
    "    \n",
    "    return ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snp_gene_pheno_df(snp_id, gene_id, snp_df_func):\n",
    "    pheno_columns = list(get_pheno_df().columns)\n",
    "    expr_df = get_expression_and_pheno_df()[pheno_columns + [gene_id]]\n",
    "    snp_df =  snp_df_func(snp_id)\n",
    "    return expr_df.merge(snp_df, left_on='BrNum', right_index=True)\n",
    "\n",
    "\n",
    "def simple_snp_expression_pheno_plot_impl(snp_id, gene_id, snp_df_func, pheno_var):\n",
    "    df = get_snp_gene_pheno_df(snp_id, gene_id, snp_df_func)\n",
    "    df['Dx'] = df.Dx.astype('category').cat.rename_categories({'Control': 'CTL', 'Schizo': 'SZ'})\n",
    "    y0 = df[gene_id].quantile(.01) - 0.26\n",
    "    y1 = df[gene_id].quantile(.99) + 0.26\n",
    "    pjd = position_jitterdodge(jitter_width=0.27)\n",
    "    p = ggplot(df, aes(x=snp_id, y=gene_id, fill=pheno_var)) \\\n",
    "    + geom_boxplot(alpha=0.4, outlier_alpha=0) \\\n",
    "    + geom_jitter(position=pjd, stroke=0, alpha=0.6) + ylim(y0, y1) \\\n",
    "    + labs(y='Residualized expression', fill='Diagnosis') \\\n",
    "    + theme_bw(base_size=20)\\\n",
    "    + theme(legend_title=element_text(face='bold'), \n",
    "            panel_grid_major=element_blank(), \n",
    "            panel_grid_minor=element_blank())\n",
    "    return p\n",
    "\n",
    "\n",
    "def simple_gwas_ordered_snp_expression_pheno_plot(snp_id, gene_id, pheno_var):\n",
    "    return simple_snp_expression_pheno_plot_impl(snp_id, gene_id, get_gwas_ordered_snp_df, pheno_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(p, fn):\n",
    "    for ext in ['png', 'pdf', 'svg']:\n",
    "        p.save(fn + '.' + ext)\n",
    "        \n",
    "        \n",
    "def gwas_annotation(snp_id):\n",
    "    return 'SZ GWAS pvalue: %.1e' % get_gwas_snp(snp_id).iloc[0]['P']\n",
    "\n",
    "\n",
    "def eqtl_annotation(snp_id, gene_id):\n",
    "    r = get_eqtl_df()[(get_eqtl_df()['variant_id']==snp_id) & \n",
    "                      (get_eqtl_df()['gene_id']==gene_id)]\n",
    "    assert len(r)==1\n",
    "    return 'eQTL nominal p-value: %.1e' % r.iloc[0]['pval_nominal']\n",
    "\n",
    "\n",
    "def de_annotation(gene_id):\n",
    "    g = get_de_df()[(get_de_df()['transcript_id'] == gene_id)]\n",
    "    return 'DE adj.P.Val: %.3f' % g.iloc[0]['adj.P.Val']\n",
    "\n",
    "\n",
    "def risk_allele_annotation(snp_id):\n",
    "    return 'SZ risk allele: %s' % get_risk_allele(snp_id)\n",
    "\n",
    "\n",
    "def gwas_annotated_eqtl_pheno_plot(snp_id, gene_id, pheno_var):\n",
    "    p = simple_gwas_ordered_snp_expression_pheno_plot(snp_id, gene_id, pheno_var)\n",
    "    de_df = get_de_df()[(get_de_df()['transcript_id'] == gene_id)]\n",
    "    gene_symbol, gene_description = get_gene_symbol(de_df.iloc[0]['gene_id'])\n",
    "    \n",
    "    title =\"\\n\".join([gene_symbol,\n",
    "                      gene_id,\n",
    "                      gwas_annotation(snp_id),\n",
    "                      risk_allele_annotation(snp_id),\n",
    "                      eqtl_annotation(snp_id, gene_id), \n",
    "                      de_annotation(gene_id)])\n",
    "    \n",
    "    p += ggtitle(title) \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(feature)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrate DEG with PGC2+CLOZUK SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = get_integration_df()\n",
    "dft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement = {1: 'Yes', -1: 'No', 0: 0}\n",
    "dft['agree_direction'] = dft.apply(agree_direction, axis=1)\n",
    "dft.agree_direction = [agreement[item] for item in dft['agree_direction']]\n",
    "\n",
    "table =  [[np.sum((dft['P']<5e-8) & ((dft['adj.P.Val']<.05))),\n",
    "           np.sum((dft['P']<5e-8) & ((dft['adj.P.Val']>=.05)))],\n",
    "          [np.sum((dft['P']>=5e-8) & ((dft['adj.P.Val']<.05))),\n",
    "           np.sum((dft['P']>=5e-8) & ((dft['adj.P.Val']>=.05)))]]\n",
    "print(table)\n",
    "fisher_exact(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft1 = dft[(dft['P']<5e-8) & ((dft['adj.P.Val']<.05))]\n",
    "df = dft1.groupby('agree_direction').size().reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binom_test(df[0].iloc[1], df[0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft2 = dft[(dft['P']<=5e-8) & (dft['adj.P.Val'] < 0.05)].copy()\n",
    "dft2['risk_allele'] = dft2['our_snp_id'].apply(get_risk_allele)\n",
    "\n",
    "direction = {-1: 'Down', 1: 'Up'}\n",
    "boolean_conv = {True: 1, False: -1}\n",
    "dft2.pgc2_a1_same_as_our_counted = [boolean_conv[item] for item in dft2['pgc2_a1_same_as_our_counted']]\n",
    "dft2['eqtl_gwas_dir'] = [direction[item] for item in np.sign(dft2['pgc2_a1_same_as_our_counted']) * np.sign(dft2['slope']) * np.sign(dft2['OR'] - 1)]\n",
    "dft2['de_dir'] = [direction[item] for item in np.sign(dft2['t'])]\n",
    "dft2['eqtl_slope'] = np.sign(dft2['pgc2_a1_same_as_our_counted']) * np.sign(dft2['OR'] - 1) * dft2['slope']\n",
    "dft2 = dft2[['gene_id', 'gene_name', 'variant_id', 'A1', 'A2', 'risk_allele', 'OR', \n",
    "             'P', 'pval_nominal', 'adj.P.Val', 'logFC', 't', 'eqtl_slope', \n",
    "             'de_dir', 'eqtl_gwas_dir', 'agree_direction']]\n",
    "dft2.to_csv('%s/integration_by_symbol.txt' % feature, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = dft2.groupby(['gene_id']).first().reset_index().sort_values('P')\n",
    "df2.groupby(['agree_direction']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.set_index('gene_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot with PGC2 risk allele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xx in range(df2.shape[0]):\n",
    "    gg = gwas_annotated_eqtl_pheno_plot(df2.iloc[xx, :].variant_id, df2.iloc[xx, :].gene_id, 'Dx')\n",
    "    print(gg)\n",
    "    label = '%s/eqtl_gwas_%s' % (feature, df2.iloc[xx, :].gene_name)\n",
    "    save_plot(gg, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
